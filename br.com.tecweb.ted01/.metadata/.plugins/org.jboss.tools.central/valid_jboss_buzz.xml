<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Red Hat Summit Virtual Experience 2021: Register today</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qxEz7hH963I/" /><category term="Uncategorized" /><category term="Burr Sutter" /><category term="red hat summit" /><category term="Summit 2021" /><author><name>Red Hat Developer</name></author><id>https://developers.redhat.com/blog/?p=878357</id><updated>2021-03-08T08:00:55Z</updated><published>2021-03-08T08:00:55Z</published><content type="html">&lt;p&gt;Automation, application deployment, and how to speed up your journey to the cloud. These and other developer hot topics will take center stage at &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/summit"&gt;Red Hat Summit 2021&lt;/a&gt;. Join thousands of your peers by &lt;a target="_blank" rel="nofollow" href="https://reg.summit.redhat.com/flow/redhat/sum21/regGeneralAttendee/login?intcmp=7013a0000026UTXAA2"&gt;registering&lt;/a&gt; for our all-new, free, two-part virtual Summit experience. Keynote speaker Burr Sutter will be delving deep into developer technologies as we come together to learn, share stories of success and failure, and turn knowledge into action.&lt;/p&gt; &lt;p&gt;We’ve reimagined this year’s Red Hat Summit as a multi-part experience that includes two no-cost virtual components in April and June, followed by a series of small-scale in-person events later in the year.&lt;/p&gt; &lt;h2&gt;Virtual Experience | &lt;a target="_blank" rel="nofollow" href="https://www.addevent.com/event/gw5377211"&gt;April 27-28, 2021&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Join us online from wherever you are in the world.&lt;/p&gt; &lt;p&gt;What to expect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Keynotes from Red Hat leaders&lt;/li&gt; &lt;li&gt;Exciting news and announcements&lt;/li&gt; &lt;li&gt;Global customer and partner spotlights&lt;/li&gt; &lt;li&gt;Live demos&lt;/li&gt; &lt;li&gt;Access to Red Hat experts&lt;/li&gt; &lt;li&gt;Games and entertainment&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Virtual Experience | &lt;a target="_blank" rel="nofollow" href="https://www.addevent.com/event/Kx5377253"&gt;June 15-16, 2021&lt;/a&gt;&lt;/h2&gt; &lt;p&gt;Build on what you learned in April in this second installment.&lt;/p&gt; &lt;p&gt;What to expect:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Seven channels of breakout sessions featuring in-depth technical content&lt;/li&gt; &lt;li&gt;Even more access to Red Hat experts&lt;/li&gt; &lt;li&gt;Customer stories and global content&lt;/li&gt; &lt;li&gt;Demos, chat lounges, and community engagement&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://reg.summit.redhat.com/flow/redhat/sum21/regGeneralAttendee/login?intcmp=7013a0000026UTXAA2"&gt;Visit the Red Hat Summit site to secure your spot at both events with one registration&lt;/a&gt;. &lt;a target="_blank" rel="nofollow" href="/summit"&gt;Bookmark this page&lt;/a&gt; for the latest Summit-related developer sessions and on-demand videos.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#38;linkname=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fred-hat-summit-virtual-experience-2021-register-today%2F&amp;#038;title=Red%20Hat%20Summit%20Virtual%20Experience%202021%3A%20Register%20today" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/" data-a2a-title="Red Hat Summit Virtual Experience 2021: Register today"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/"&gt;Red Hat Summit Virtual Experience 2021: Register today&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qxEz7hH963I" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Automation, application deployment, and how to speed up your journey to the cloud. These and other developer hot topics will take center stage at Red Hat Summit 2021. Join thousands of your peers by registering for our all-new, free, two-part virtual Summit experience. Keynote speaker Burr Sutter will be delving deep into developer technologies as [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/"&gt;Red Hat Summit Virtual Experience 2021: Register today&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">878357</post-id><dc:creator>Red Hat Developer</dc:creator><dc:date>2021-03-08T08:00:55Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/red-hat-summit-virtual-experience-2021-register-today/</feedburner:origLink></entry><entry><title>New developer quick starts and more in the Red Hat OpenShift 4.7 web console</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ihpK80S_v6g/" /><category term="CI/CD" /><category term="Kubernetes" /><category term="Operator" /><category term="Serverless" /><category term="helm charts" /><category term="openshift" /><category term="serverless" /><category term="Tekton" /><author><name>Serena Chechile Nichols</name></author><id>https://developers.redhat.com/blog/?p=873037</id><updated>2021-03-08T08:00:26Z</updated><published>2021-03-08T08:00:26Z</published><content type="html">&lt;p&gt;We are continuing to evolve the developer experience in &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com"&gt;Red Hat OpenShift 4.7&lt;/a&gt;. This article highlights what&amp;#8217;s new for developers in the OpenShift 4.7 web console. Keep reading to learn about exciting changes to the topology view, an improved developer catalog experience, new developer quick starts, user interface support for &lt;a target="_blank" rel="nofollow" href="/courses/middleware/openshift-pipelines"&gt;Red Hat OpenShift Pipelines&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="/topics/serverless-architecture"&gt;Red Hat OpenShift Serverless&lt;/a&gt;, and more.&lt;/p&gt; &lt;h2&gt;Quick-add in the topology view&lt;/h2&gt; &lt;p&gt;One of my favorite features in OpenShift 4.7 is the new quick-add option in the web console&amp;#8217;s topology view. You can use this UI control to search for an item from the developer catalog directly from the topology view without changing context. As you type, matches are dynamically shown in a list. You can then click on a match to see a quick overview in the right panel, then click on the call-to-action to install it. The demonstration in Figure 1 shows the new quick-add feature.&lt;/p&gt; &lt;div id="attachment_877827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/quickadd.gif"&gt;&lt;img aria-describedby="caption-attachment-877827" class="wp-image-877827 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4.7-fig1.gif" alt="An animated demonstration of the quick-add feature." width="640" height="348" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877827" class="wp-caption-text"&gt;Figure 1: The new quick-add feature in the OpenShift web console&amp;#8217;s topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Additionally, the web console now offers persistent storage for user settings so that you can persist layouts in the topology view. We&amp;#8217;ve had many requests for this feature, shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_877837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/topology-layout.gif"&gt;&lt;img aria-describedby="caption-attachment-877837" class="wp-image-877837 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4-7-fig2.gif" alt="A demonstration of persistence in the topology graph layouts." width="640" height="369" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877837" class="wp-caption-text"&gt;Figure 2: Topology graph layouts are now persisted.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;New features in the developer catalog&lt;/h2&gt; &lt;p&gt;The developer catalog is a one-stop-shop for developers to get started quickly with OpenShift. We have improved the developer experience in OpenShift 4.7 by creating a consistent experience across catalogs while also offering contextual views for specific catalog types.&lt;/p&gt; &lt;p&gt;When entering the developer catalog, users can now view all content in a single catalog. Several sub-catalogs are available by default: Builder images, Helm charts, Operator-backed services, and samples. Other sub-catalogs are available based on the installed &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes/operators"&gt;Operators&lt;/a&gt;. OpenShift 4.7 has sub-catalogs for event sources and virtual machines, and more are coming in future releases.&lt;/p&gt; &lt;p&gt;When you drill into sub-catalogs, the features and filters exposed are specific to a given catalog type. As an example, did you know that administrators can add multiple Helm chart repositories? The Helm chart catalog exposes charts from multiple repositories and lets you filter by any Helm chart repository.&lt;/p&gt; &lt;p&gt;Finally, we have received many requests to allow administrators to customize the developer catalog experience. In OpenShift 4.7, we&amp;#8217;ve added a customization feature for catalog administrators. To modify the developer catalog&amp;#8217;s available categories, you only need to add a customization section to the console operator resource. You can then use the resulting YAML snippet to add the default categories to start with and edit them from there.&lt;/p&gt; &lt;h2&gt;Developer quick starts&lt;/h2&gt; &lt;p&gt;You can now access developer quick starts from the &lt;b&gt;+Add&lt;/b&gt; page or from the &lt;b&gt;Quick Starts&lt;/b&gt; item in the OpenShift web console&amp;#8217;s &lt;b&gt;Help&lt;/b&gt; menu. The quick-starts catalog, shown in Figure 3, offers a variety of new developer quick starts—try one out!&lt;/p&gt; &lt;div id="attachment_873397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev.png"&gt;&lt;img aria-describedby="caption-attachment-873397" class="wp-image-873397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-1024x562.png" alt="Tiles represent quick starts in the catalog." width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/QuickStartsForTheDev-768x421.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-873397" class="wp-caption-text"&gt;Figure 3: Developer quick starts in the quick-starts catalog.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Tekton pipelines&lt;/h2&gt; &lt;p&gt;The OpenShift 4.7 web console offers a couple of enhancements for Tekton pipelines. For one, you can now easily access your Tekton pipeline metrics, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_873377" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics.png"&gt;&lt;img aria-describedby="caption-attachment-873377" class="wp-image-873377 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-1024x615.png" alt="A demonstration of viewing Tekton metrics in the console." width="640" height="384" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-1024x615.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-300x180.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/PipelineMetrics-768x461.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-873377" class="wp-caption-text"&gt;Figure 4: Tekton pipeline metrics.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We&amp;#8217;ve also enhanced the &lt;b&gt;PipelineRun&lt;/b&gt; details page, as demonstrated in Figure 5.&lt;/p&gt; &lt;div id="attachment_877857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/PLREnhancements.gif"&gt;&lt;img aria-describedby="caption-attachment-877857" class="wp-image-877857 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/03/rh-openshift-console-4-7-fig5.gif" alt="A demonstration of viewing the PipelineRun details page." width="640" height="369" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-877857" class="wp-caption-text"&gt;Figure 5: The improved PipelineRun details page.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From the &lt;b&gt;Events&lt;/b&gt; tab, you can now easily access events related to the &lt;code&gt;PipelineRun&lt;/code&gt;, including &lt;code&gt;TaskRun&lt;/code&gt; and pod events. You can also download logs from the &lt;b&gt;Logs&lt;/b&gt; tab.&lt;/p&gt; &lt;h2&gt;Serverless&lt;/h2&gt; &lt;p&gt;Web console support for OpenShift Serverless includes the ability to create channels. Once created, brokers and channels are displayed in the topology view. In addition to creating subscriptions and triggers from action menus, you can now drag-and-drop to initiate these actions from the topology view.&lt;/p&gt; &lt;p&gt;We have also enhanced the creation flow for event sources. Event sources are custom resources, and we needed to address scalability issues in this feature, so we’ve changed the user experience to be catalog-based. You can now view event sources along with other objects in the service catalog. Alternatively, you can click on the event source type and drill into a catalog solely focused on event sources. As an example, if you had the &lt;a target="_blank" rel="nofollow" href="/integration"&gt;Red Hat Integration&lt;/a&gt; &lt;a target="_blank" rel="nofollow" href="/topics/camel-k"&gt;Camel K&lt;/a&gt; Operator installed, you would see Camel K connectors in the catalog.&lt;/p&gt; &lt;p&gt;We’ve also updated the administrator perspective for OpenShift Serverless. The web console includes a primary navigation section for OpenShift Serverless, which contains two sub-sections. One sub-section focuses on serving resources, and the other is for eventing. You can navigate to these sections to find details about your OpenShift event sources, brokers, triggers, channels, and subscriptions. These items are also accessible in the developer perspective&amp;#8217;s topology view and on the search page.&lt;/p&gt; &lt;h2&gt;We want your feedback&lt;/h2&gt; &lt;p&gt;Community feedback helps us continually improve the OpenShift developer experience, and we want to hear from you. You can attend our office hours on &lt;a target="_blank" rel="nofollow" href="http://openshift.tv"&gt;Red Hat OpenShift Streaming&lt;/a&gt; or join the &lt;a target="_blank" rel="nofollow" href="https://groups.google.com/forum/#!forum/openshift-dev-users"&gt;OpenShift Developer Experience Google group&lt;/a&gt;. We hope you will share your tips for using the OpenShift web console, get help with what doesn’t work, and shape the future of the OpenShift developer experience. Ready to get started? &lt;a target="_blank" rel="nofollow" href="http://www.openshift.com/try"&gt;Try OpenShift today&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#38;linkname=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fnew-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console%2F&amp;#038;title=New%20developer%20quick%20starts%20and%20more%20in%20the%20Red%20Hat%20OpenShift%204.7%20web%20console" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/" data-a2a-title="New developer quick starts and more in the Red Hat OpenShift 4.7 web console"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/"&gt;New developer quick starts and more in the Red Hat OpenShift 4.7 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ihpK80S_v6g" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;We are continuing to evolve the developer experience in Red Hat OpenShift 4.7. This article highlights what&amp;#8217;s new for developers in the OpenShift 4.7 web console. Keep reading to learn about exciting changes to the topology view, an improved developer catalog experience, new developer quick starts, user interface support for Red Hat OpenShift Pipelines and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/"&gt;New developer quick starts and more in the Red Hat OpenShift 4.7 web console&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">873037</post-id><dc:creator>Serena Chechile Nichols</dc:creator><dc:date>2021-03-08T08:00:26Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/new-developer-quick-starts-and-more-in-the-red-hat-openshift-4-7-web-console/</feedburner:origLink></entry><entry><title>What’s new in Red Hat OpenShift’s Web Terminal Operator 1.2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/KxWHVnxmaAk/" /><category term="DevOps" /><category term="Kubernetes" /><category term="Linux" /><category term="Operator" /><category term="openshift" /><category term="OpenShift Operator" /><category term="web console" /><category term="Web Terminal Operator" /><author><name>jpinkney</name></author><id>https://developers.redhat.com/blog/?p=872357</id><updated>2021-03-08T08:00:11Z</updated><published>2021-03-08T08:00:11Z</published><content type="html">&lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;&amp;#8216;s Web Terminal Operator is a way for users to access a web terminal with common cluster tooling pre-installed. This gives you the power and flexibility to work with your product directly through the OpenShift web console, eliminating the need to have all your tooling installed locally.&lt;/p&gt; &lt;p&gt;This article is an overview of the new features introduced in Web Terminal Operator 1.2. These improvements include allowing cluster administrators to securely access the terminal, more information for users when a terminal has shut down due to inactivity, and a tooling update to align with OpenShift 4.7.&lt;/p&gt; &lt;h2&gt;Easier access to the OpenShift web console&lt;/h2&gt; &lt;p&gt;In Web Terminal Operator 1.2, cluster administrators can access the web terminal directly, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_872407" style="width: 650px" class="wp-caption alignnone"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-1.gif"&gt;&lt;img aria-describedby="caption-attachment-872407" class="wp-image-872407" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-1.gif" alt="A cluster administrator accessing the web terminal on the OpenShift web console." width="640" height="332" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-872407" class="wp-caption-text"&gt;Figure 1: Opening the web terminal as a cluster administrator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, everyone on your cluster can access their own web terminal, regardless of their permission level. Note that for security reasons, cluster administrators will automatically bypass the namespace picker and have their web terminal created in the &lt;code&gt;openshift-terminal&lt;/code&gt; namespace. Other than that, the functionality remains the same as that of a user without the cluster-admin role.&lt;/p&gt; &lt;h2&gt;Understanding why a terminal has stopped&lt;/h2&gt; &lt;p&gt;To conserve resources, the web terminal automatically shuts down after 15 minutes of inactivity. In Web Terminal Operator 1.2, we’ve added more information to help users understand why a terminal has stopped (see Figure 2).&lt;/p&gt; &lt;div id="attachment_872417" style="width: 650px" class="wp-caption alignnone"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2.png"&gt;&lt;img aria-describedby="caption-attachment-872417" class="wp-image-872417" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2.png" alt="The web console informing the user that the terminal has closed due to inactivity." width="640" height="333" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2.png 821w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-2-768x399.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-872417" class="wp-caption-text"&gt;Figure 2: The terminal window indicating why a terminal has shut down.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Web Terminal Operator 1.2 also offers an easier way to restart the terminal with the click of a button, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_872427" style="width: 649px" class="wp-caption alignnone"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-3.gif"&gt;&lt;img aria-describedby="caption-attachment-872427" class="wp-image-872427" src="https://developers.redhat.com/blog/wp-content/uploads/2021/02/Figure-3.gif" alt="Clicking the Restart terminal button to restart the session." width="639" height="336" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-872427" class="wp-caption-text"&gt;Figure 3: Click &lt;b&gt;Restart terminal&lt;/b&gt; to restart a session.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Updated tooling&lt;/h2&gt; &lt;p&gt;We have updated the default binaries in Web Terminal Operator 1.2 to include the latest versions of the built-in command-line tools, as shown in Table 1.&lt;/p&gt; &lt;table align="”center”"&gt; &lt;caption&gt;&lt;b&gt;Table 1: Command-line tools in Web Terminal Operator 1.2&lt;/b&gt;&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;Binary&lt;/th&gt; &lt;th&gt;Old version&lt;/th&gt; &lt;th&gt;New version&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;oc&lt;/code&gt;&lt;/td&gt; &lt;td&gt;4.6.1&lt;/td&gt; &lt;td&gt;4.7.0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/td&gt; &lt;td&gt;1.19.0&lt;/td&gt; &lt;td&gt;1.20.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;odo&lt;/code&gt;&lt;/td&gt; &lt;td&gt;2.0.0&lt;/td&gt; &lt;td&gt;2.0.4&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;helm&lt;/code&gt;&lt;/td&gt; &lt;td&gt;3.3.4&lt;/td&gt; &lt;td&gt;3.5.0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;kn&amp;#60;/code&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.16.1&lt;/td&gt; &lt;td&gt;0.19.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;tkn&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.11.0&lt;/td&gt; &lt;td&gt;0.15.0&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;For a peek into how the Web Terminal Operator works under the hood, see &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/a-deeper-look-at-the-web-terminal-operator-1"&gt;&lt;i&gt;A deeper look at the Web Terminal Operator&lt;/i&gt;&lt;/a&gt; by Angel Misevski. You can also check out the initial release article by Joshua Wood: &lt;a target="_blank" rel="nofollow" href="/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview/"&gt;&lt;i&gt;Command-line cluster management with Red Hat OpenShift’s new web terminal&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fwhats-new-in-red-hat-openshifts-web-terminal-operator-1-2%2F&amp;#038;title=What%E2%80%99s%20new%20in%20Red%20Hat%20OpenShift%E2%80%99s%20Web%20Terminal%20Operator%201.2" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/" data-a2a-title="What’s new in Red Hat OpenShift’s Web Terminal Operator 1.2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/"&gt;What&amp;#8217;s new in Red Hat OpenShift&amp;#8217;s Web Terminal Operator 1.2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/KxWHVnxmaAk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;&amp;#160; Red Hat OpenShift&amp;#8216;s Web Terminal Operator is a way for users to access a web terminal with common cluster tooling pre-installed. This gives you the power and flexibility to work with your product directly through the OpenShift web console, eliminating the need to have all your tooling installed locally. This article is an overview [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/"&gt;What&amp;#8217;s new in Red Hat OpenShift&amp;#8217;s Web Terminal Operator 1.2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">872357</post-id><dc:creator>jpinkney</dc:creator><dc:date>2021-03-08T08:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2/</feedburner:origLink></entry><entry><title>Introduction to the Node.js reference architecture, Part 1: Overview</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pilWCtxrdN0/" /><category term="JavaScript" /><category term="Node.js" /><category term="Open source" /><category term="npm" /><category term="reference architecture" /><author><name>Michael Dawson</name></author><id>https://developers.redhat.com/blog/?p=865807</id><updated>2021-03-08T08:00:06Z</updated><published>2021-03-08T08:00:06Z</published><content type="html">&lt;p&gt;Welcome to this new series introducing the &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture&lt;/a&gt; from Red Hat and IBM. This article is an overview of our reasons for developing the Node.js reference architecture—both what we hope the architecture will offer our developer community and what we &lt;em&gt;do not&lt;/em&gt; intend it to do. Future articles will offer a detailed look at different sections of the reference architecture.&lt;/p&gt; &lt;p&gt;Before we dive into this first article, it&amp;#8217;s important to acknowledge that the &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; reference architecture is a work in progress. The development team is working through different areas, discussing what we&amp;#8217;ve learned, and distilling that information into concise recommendations and guidance. Given the fast pace of development in the &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; ecosystem, the reference architecture might never be “finished.” Instead, we&amp;#8217;ll continue updating it to reflect what we learn through new Node.js production deployments and ongoing experience with our deployments at scale. The reference architecture is meant to reflect our current experience and thinking, which will evolve.&lt;/p&gt; &lt;h2&gt;Why we need a Node.js reference architecture&lt;/h2&gt; &lt;p&gt;The JavaScript ecosystem is fast-moving and vibrant. You only need to look at the &lt;a target="_blank" rel="nofollow" href="http://www.modulecounts.com/"&gt;growth rate of Node Package Manager (npm) modules&lt;/a&gt; to see that. In 2016, there were approximately 250,000 npm packages. In 2018, that number climbed to around 525,000, and in 2020 it was roughly 1.1 million. These numbers represent considerable choice and variety in the JavaScript ecosystem. That is clearly a strength for flourishing innovation and testing new ideas.&lt;/p&gt; &lt;p&gt;On the flip side, the wide variety of options can make choosing among Node.js packages very difficult. For any module, you might find several equally good choices, as well as several potentially very bad choices. Every application has a “secret sauce” that is key to its success. It is imperative to find the best fitting, newest, or most innovative package to use for this area of the application. For the rest of the application, you likely want something that works and for which you can share any experiences or best practices across your organization. In the latter case, having a reference architecture can help teams avoid relearning the same things again and again.&lt;/p&gt; &lt;h2&gt;What the reference architecture is&lt;/h2&gt; &lt;p&gt;Our Node.js teams at Red Hat and IBM can&amp;#8217;t be experts on 1.1 million JavaScript packages in the &lt;code&gt;npm&lt;/code&gt; registry. Similarly, we can&amp;#8217;t be involved in all of the projects to the level that we are involved in the Node.js project. Instead, our experience is based on our broad usage of Node.js. This includes large-scale deployments like the &lt;a target="_blank" rel="nofollow" href="https://developer.ibm.com/languages/node-js/articles/nodejs-weather-company-success-story/"&gt;Weather Company&lt;/a&gt;, as well as the work that our consulting groups do with customers.&lt;/p&gt; &lt;p&gt;If every internal team and customer who asks for help with their Node.js application uses different packages, it will be much harder to help them. The question is, how do we share our knowledge across the organization?&lt;/p&gt; &lt;p&gt;We want to help our internal teams and customers make good choices and deployment decisions. In cases where a team doesn&amp;#8217;t need to use a specific package, we can recommend a package based on the experience we’ve built across Red Hat and IBM. As developers, we can use the Node.js reference architecture to share and collaborate across teams and projects and establish common ground within our deployments.&lt;/p&gt; &lt;h2&gt;What the reference architecture is not&lt;/h2&gt; &lt;p&gt;I have described what we hope to do with the Node.js reference architecture. It is just as important to be clear about what we are &lt;em&gt;not&lt;/em&gt; trying to do.&lt;/p&gt; &lt;p&gt;First, the reference architecture is not an attempt to convince or force developers to use the packages we choose. Deployments are varied, and there will be good reasons to use specific modules in different circumstances.&lt;/p&gt; &lt;p&gt;Second, we do not claim that our recommendations are better than the alternatives. As I noted, you will often find several equally good packages or approaches available in the JavaScript ecosystem. Our recommendations favor what the Red Hat and IBM teams have used successfully and the technologies we are familiar with. We are not attempting to steer anyone to the “best” choice but instead to a “good” choice. Having a reference architecture maximizes the likelihood of leveraging lessons already learned and having common ground so that we can help each other.&lt;/p&gt; &lt;h2&gt;About this series&lt;/h2&gt; &lt;p&gt;The Node.js development team is having interesting discussions as we work through each section of the reference architecture. At the same time, we are trying to keep the reference architecture&amp;#8217;s content concise and to the point. As I&amp;#8217;ve mentioned, the goal is to provide good choices for the application&amp;#8217;s general architecture so that developers can focus on the application&amp;#8217;s &amp;#8220;secret sauce.&amp;#8221; In most cases, developers using the reference architecture will want to know what package or technology to use and how. As a result, the reference architecture won&amp;#8217;t include much about the interesting background and discussions that led to our decisions.&lt;/p&gt; &lt;p&gt;This series &lt;em&gt;will&lt;/em&gt; share the viewpoints gained from our internal discussions. As we work through each section of the reference architecture, we&amp;#8217;ll use this series to offer additional references and an opportunity to dive into more detail on related topics. I think you’ll find the varied experience of developers across the Node.js team gets you thinking. I learn something from every section we go through, and I hope you will, too.&lt;/p&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;We plan to cover new topics regularly as part of this series. While you wait for the next installment, we invite you to visit the &lt;a target="_blank" rel="nofollow" href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture repository&lt;/a&gt; on GitHub. You&amp;#8217;ll be able to see the work we&amp;#8217;ve already done and the kinds of topics you can look forward to from this series. To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js landing page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#38;linkname=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F08%2Fintroduction-to-the-node-js-reference-architecture-part-1-overview%2F&amp;#038;title=Introduction%20to%20the%20Node.js%20reference%20architecture%2C%20Part%201%3A%20Overview" data-a2a-url="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/" data-a2a-title="Introduction to the Node.js reference architecture, Part 1: Overview"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Introduction to the Node.js reference architecture, Part 1: Overview&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pilWCtxrdN0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Welcome to this new series introducing the Node.js reference architecture from Red Hat and IBM. This article is an overview of our reasons for developing the Node.js reference architecture—both what we hope the architecture will offer our developer community and what we do not intend it to do. Future articles will offer a detailed look [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Introduction to the Node.js reference architecture, Part 1: Overview&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">865807</post-id><dc:creator>Michael Dawson</dc:creator><dc:date>2021-03-08T08:00:06Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/</feedburner:origLink></entry><entry><title type="html">Supply chain integration - An architectural introduction</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/RglmmpBvDao/supply-chain-integration-an-architectural-introduction.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/pvxTT3ZYk8A/supply-chain-integration-an-architectural-introduction.html</id><updated>2021-03-08T06:00:00Z</updated><content type="html">Part 1 - An architectural introduction If you've been following my writing over the last few years, you've grown accustomed to my sharing of various architecture blueprints. They're focusing on presenting access to ways of mapping successful implementations for specific use cases. It's an interesting challenge in our mission of creating of architectural content based on common customer adoption patterns. That's very different from most of the traditional marketing activities usually associated with generating content for the sole purpose of positioning products for solutions. When you're basing the content on actual execution in solution delivery, you're cutting out the chuff.  What's that mean? It means that it's going to provide you with a way to implement a solution using open source technologies by focusing on the integrations, structures and interactions that actually have been proven to work. What's not included are any vendor promises that you'll find in normal marketing content. Those promised that when it gets down to implementation crunch time, might not fully deliver on their promises. Enter the term Architectural Blueprint.  Let's look at these blueprints, how their created and what value they provide for your solution designs. THE PROCESS The first step is to decide the use case to start with, which in my case had to be linked to a higher level theme that becomes the leading focus. This higher level theme is not quite boiling the ocean, but it's so broad that it's going to require some division in to smaller parts. In this case we've aligned with the higher level theme being 'Retail' use cases, a vertical focus. This breaks down into the following use cases and in no particular order: * * * Point of sale * Headless eCommerce * Store health and safety * Real-time stock control * Retail data framework The case I'm tackling here is focused on supply chain integration. This use case we've defined as the following: Streamlining integration between different elements of a retail supply chain for on-premise, cloud, and other third-party interactions. The approach taken is to research our existing customers that have implemented solutions in this space, collect their public facing content, research the internal implementation documentation collections from their successful engagements, and where necessary reach out to the field resources involved.  To get an idea of what these blueprints look like, we refer you to the series previously discussed here: * * * * Now on to the task at hand. WHAT'S NEXT The resulting content for this project targets the following three items. * A slide deck of the architectural blueprint for use telling the portfolio solution story. * Generic architectural diagrams providing the general details for the portfolio solution. * A write-up of the portfolio solution in a series that can be used for a customer solution brief. An overview of this series on business optimisation portfolio architecture blueprint: 1. 2. Common architectural elements 3. Example of supply chain integration Catch up on any past articles you missed by following any published links above. Next in this series, taking a look at the generic common architectural elements for the supply chain integration architecture. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/RglmmpBvDao" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/pvxTT3ZYk8A/supply-chain-integration-an-architectural-introduction.html</feedburner:origLink></entry><entry><title type="html">Starting business processes using Kafka events</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lOnWfH1OUk8/starting-business-processes-using-kafka-events.html" /><author><name>Karina Varela</name></author><id>https://blog.kie.org/2021/03/starting-business-processes-using-kafka-events.html</id><updated>2021-03-07T23:30:57Z</updated><content type="html">Let’s check how we can model a business process, using the BPMN standard, that can react to events. Whenever a new event is published in a specific Kafka topic, a new process instance should be started. We’ll also check how to configure the project and environment in order to achieve these goals. GETTING STARTED To get started we should create, deploy and test an event-driven process application.  1. PREPARING YOUR ENVIRONMENT The samples described in this guide were created using the following technologies: * Java 11 * Maven, Git *  7.48+ or  7.10+ * Kafka  INFO: This feature was released in this specific jBPM and RHPAM version. To achieve this post’s goals, you must use the mentioned versions or higher. If you don’t know how to install jBPM locally, take a look at: . 1.1. PREPARING YOUR KAFKA SERVER AND TOPICS Event-driven processes interacts with other services via event platforms, more specifically in our case, Kafka topics. In this application, our process needs interacts with three topics: “incoming-requests“, “requests-approved” and “requests-denied“. Let’s now setup a Kafka environment and create these three topics. We will use Strimzi and docker compose to help us get up and running faster. INFO: This guide focus is not Kafka, therefore the following steps are straightforward. If you need more details about the upcoming commands please refer to this post: . First, clone the project that contains the docker-compose file we’ll use to start the Kafka services. Next start the services. Check the commands below: git clone cd amq-examples/strimzi-all-in-one/ docker-compose up Open a new tab in your terminal, access the cloned project folder (amq-examples/strimzi-all-in-one/) and create the three topics: docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic incoming-requests docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic requests-approved docker-compose exec kafka bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic requests-denied Now that we have the three topics ready to be used as our communication layer between services and our process, we can start working on the process definition. THE USE CASE AND THE SHIFT TO AN EVENT-DRIVEN PROCESS APPLICATION Our use case will be the automation of a credit card limit raise approval process. Most card issuers allow customers to request an increased credit limit through their websites, mobile apps or over the phone. Let’s consider we need to deliver this automation for a bank that wants to achieve a similar use case within an event-driven architecture. TIP: We’ll simplify the business logic of this use case to give focus to the eventing features and how you can use it. The existing process is started via REST. It has a step for automatic request validation using DMN, and if the request not approved, it goes to a manual analysis. If approved, the service responsible for updating the cc limit is invoked via REST (the diagram only represents this REST call with a script task since this is not relevant for this guide’s scenario). Finally, the process ends either with an approved or denied request. Image 1: Process v1. The process starts based on a rest call or JAVA API invocation. Services involved in the process are invoked via rest. Now, with the architecture shift, the service responsible for increasing the credit card limit should not be invoked via REST anymore. The external service now listens to the topic “request-approved” in order to track when to execute the limit raise. The business process should get started based on events, and whenever the process finishes, it should post a message to a specific topic depending on whether the request was approved or not. Notice how the process below can achieve the same goals, using an event-driven strategy: Image 2: Process v2. Whenever a new event happens in a topic, a new instance will be triggered. Depending on how this process ends, an event is published in a different topic, therefore, different services can react based on the approval status. In this strategy we have a resilient way of communication between services where the broker is responsible for storing and providing the events. Adding to that, the tech team can evolve the solutions by using the features available in Kafka itself, like the possibility to replay all the events that happened in a specific time, in chronological order. 2. ENABLING THE JBPM (RHPAM) KAFKA EXTENSION To enable Kafka capabilities in the KIE Server (engine) we need to use system properties in the runtime environment. You can enable it both for SpringBoot and WildFly (a.k.a. jBoss) based deployments. See below the command that uses the jboss-cli.sh (or .bat) script to add the system property in WildFly, and, restart it. TIP: When adding new system properties to WildFly or jBoss EAP, it’s necessary to restart it to have the new system properties activated. INFO: There are more options in jBPM to customize the Kafka address, topic names, etc. In our case, we’re using the default Kafka address, which is, localhost:9092. More customization information can be found in the official Red Hat product documentation: . With WildFly or EAP up and running, you can enable the Kafka extension in the KIE Server by executing the commands below: $ $JBOSS_HOME/bin/jboss-cli.sh -c [standalone@localhost:9990 /] /system-property=org.kie.kafka.server.ext.disabled:add(value=false) [standalone@localhost:9990 /] :shutdown(restart=true) We’re now ready to start working on the process definition. 3. STARTING PROCESSES USING EVENTS * First, import the existing project with process v1 in Business Central. * Open the cc-limit-raise-approval process. * The first step is to change the start event to a start message event: Image 3: Convert start event to start message event Whenever a customer do a new request (independently of the channel used) an event should be published on the “new-requests” topic. With that, a new process instance will be started whenever a new event is published in this topic. * Configure the name of the Kafka topic in the starting message event. Image 4: Configure the message with the same name of the topic it will listen to. * We want to receive the request contained in the event data. The engine provides automatic marshalling to help us mapping the input directly to a data object. The project has an object named “LimitRaiseRequest.java” which we will use to receive the incoming data. On the properties panel of the Start Message Event, configure the input data: Image 5: Start message event configuration of the Input data * Save the process. * Now, deploy the project to KIE Server so you can test it. You can use the deploy button available in Business Central. * Open a new tab in the terminal, and access the “” project we’re using to interact with the Kafka service. cd $PROJECTS_DIR/amq-examples/strimzi-all-in-one docker-compose exec kafka bin/kafka-console-producer.sh --topic incoming-requests --bootstrap-server localhost:9092 &gt; The producer service is now waiting for you to publish an event to the topic “incoming-requests“. To do so, simply input the following json data and hit enter: {"data" : {"customerId": 1, "customerScore": 250, "requestedValue":1500}} &gt; {"data" : {"customerId": 1, "customerScore": 250, "requestedValue":1500}} * Now, in your browser, in Business Central, if you go to the Process Instances management page and filter by the Completed status, you should be able to see a process instance completed: Image 6: Business Central. List of completed process instances in the monitored KIE Server. * Select the process instance you see, and next, go the the Diagram tab. You should see that the request was automatically approved. Image 7: Process Instance Diagram. This process instance was started based on an event that happened in the topic configured in the message start event. -------------------------------------------------------------------------------- You can now effectively handle the events that triggers business processes within an event-driven architecture. The next step is to learn how to emit events from within your process. The following post should bring you details on how to let the ecosystem know about key happenings of your business process. -------------------------------------------------------------------------------- This blog post is part of the seventh section of the  series: . The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lOnWfH1OUk8" height="1" width="1" alt=""/&gt;</content><dc:creator>Karina Varela</dc:creator><feedburner:origLink>https://blog.kie.org/2021/03/starting-business-processes-using-kafka-events.html</feedburner:origLink></entry><entry><title>Making environment variables accessible in front-end containers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/bRQAOiM1CwA/" /><category term="Containers" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="angular" /><category term="environment variables" /><category term="front-end containers" /><category term="react" /><category term="VueJS" /><author><name>Joel Lord</name></author><id>https://developers.redhat.com/blog/?p=861157</id><updated>2021-03-04T18:59:36Z</updated><published>2021-03-04T18:59:36Z</published><content type="html">&lt;p&gt;When &lt;a href="https://developers.redhat.com/topics/containers"&gt;building a container&lt;/a&gt; for a single-page application using any modern &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript framework&lt;/a&gt; (such as Angular, React, or Vue.js), you might find that the configuration settings are different depending on where the container will run. A typical case would be the base URL for your API, which will differ depending on whether you are testing the application or deploying it into production. Developers usually solve this problem using environment variables.&lt;/p&gt; &lt;p&gt;Environment variables typically work on the backend because that is where code runs. But what if your application lives in the user&amp;#8217;s browser? There are many ways around this limitation. In some cases, you might build a server whose endpoint holds the necessary parameters. Another workaround is to use PHP to inject the environment variables as globals in the JavaScript code. Both of these options work, but it would be ideal to inject the environment variables as part of the container build process. That way, you don&amp;#8217;t have to change the codebase, and you can still deliver the application content using a static web server like NGINX.&lt;/p&gt; &lt;p&gt;This article shows you how to inject environment variables directly into your codebase as you build your container.&lt;/p&gt; &lt;h2&gt;JavaScript frameworks in the production build&lt;/h2&gt; &lt;p&gt;It doesn&amp;#8217;t matter which JavaScript framework you use—React, Angular, or Vue.js—because they all work virtually the same way. The framework runs a server that watches the files, and it refreshes the browser when a change is detected. This process is excellent for development purposes but not so much for production servers. All of that code requires too many resources to run. For the application content to work in a web server, we need a build step that minimizes the code and keeps only the necessary parts. We can then create a package using a single page that contains all of the application&amp;#8217;s HTML, JavaScript, and CSS. When a container runs in a production environment, it will serve this minified package.&lt;/p&gt; &lt;p&gt;It turns out that the container-build step that prepares your code for production is also a great place to inject environment variables. We&amp;#8217;ll go through the process in the next sections.&lt;/p&gt; &lt;h2&gt;Create a skeleton application&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s start with a skeleton application built with the command-line interface (CLI) for your JavaScript framework:&lt;/p&gt; &lt;pre&gt;# Angular npx @angular/cli new angular-project # React npx create-react-app react-project # VueJS npx @vue/cli create vue-project &lt;/pre&gt; &lt;p&gt;For your project of choice, create a &lt;code&gt;config.json&lt;/code&gt; file in the &lt;code&gt;/src&lt;/code&gt; folder. This file will contain settings that could change based on the environment. In this case, it will have two properties: One to specify the environment and another one for the base URL of your imaginary API:&lt;/p&gt; &lt;pre&gt;{ "ENV": "development", "BASE_URL": "http://localhost:3000" }&lt;/pre&gt; &lt;p&gt;For simplicity, the application you are using will display those values on the main page. Head over to your main page, import the configuration file, and display both values in that view.&lt;/p&gt; &lt;p&gt;Next, we&amp;#8217;ll look at the application-specific code for Angular, React, and Vue.js.&lt;/p&gt; &lt;h3&gt;Angular&lt;/h3&gt; &lt;p&gt;To import a JSON file, you might need to add the following options to the &lt;code&gt;compilerOptions&lt;/code&gt; of your &lt;code&gt;tsconfig.json&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt; "resolveJsonModule": true, "esModuleInterop": true, "allowSyntheticDefaultImports": true, &lt;/pre&gt; &lt;p&gt;Here are the application components (&lt;code&gt;src/app/app.component.ts&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;import { Component } from '@angular/core'; import Config from "../config.json"; @Component({ selector: 'app-root', templateUrl: './app.component.html' }) export class AppComponent { environment = Config.ENV; baseUrl = Config.BASE_URL; }&lt;/pre&gt; &lt;p&gt;Here is the application HTML (&lt;code&gt;src/app/app.component.html&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&amp;#60;div&amp;#62; &amp;#60;p&amp;#62;Environment: {{ environment }}&amp;#60;/p&amp;#62; &amp;#60;p&amp;#62;Base Url: {{ baseUrl }}&amp;#60;/p&amp;#62; &amp;#60;/div&amp;#62; &lt;/pre&gt; &lt;h3&gt;React&lt;/h3&gt; &lt;p&gt;Here&amp;#8217;s an application config for React (&lt;code&gt;src/App.js&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;import Config from "./config.json"; function App() { const environment = Config.ENV; const baseUrl = Config.BASE_URL; return ( &amp;#60;div&amp;#62; &amp;#60;p&amp;#62;Environment: { environment }&amp;#60;/p&amp;#62; &amp;#60;p&amp;#62;Base Url: { baseUrl }&amp;#60;/p&amp;#62; &amp;#60;/div&amp;#62; ); } export default App;&lt;/pre&gt; &lt;h3&gt;Vue.js&lt;/h3&gt; &lt;p&gt;And here&amp;#8217;s the configuration for Vue.js (&lt;code&gt;src/App.vue&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&amp;#60;template&amp;#62; &amp;#60;div&amp;#62; &amp;#60;p&amp;#62;Environment: {{ environment }}&amp;#60;/p&amp;#62; &amp;#60;p&amp;#62;Base Url: {{ baseUrl }}&amp;#60;/p&amp;#62; &amp;#60;/div&amp;#62; &amp;#60;/template&amp;#62; &amp;#60;script&amp;#62; import Config from "./config.json"; export default { name: 'App', data: () =&amp;#62; { return { environment: Config.ENV, baseUrl: Config.BASE_URL } } } &amp;#60;/script&amp;#62; &lt;/pre&gt; &lt;h2&gt;Multi-stage build containers&lt;/h2&gt; &lt;p&gt;Now, you&amp;#8217;re ready to build the front-end container. For this process, you will use a container to create the production version of the application. Docker will then copy this build function&amp;#8217;s output into a second container, an NGINX server. Once the second container is created, you discard the first container. What&amp;#8217;s left is the NGINX server with the minimal set of files from the prior stage.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s start by creating an image to contain the application. Later, we&amp;#8217;ll come back to apply the environment variables. For this stage, you&amp;#8217;ll do the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a new file called &lt;code&gt;Dockerfile&lt;/code&gt;. The first stage uses a &lt;code&gt;node:14&lt;/code&gt; image to build the production version of the application. Copy over all of your files into the container.&lt;/li&gt; &lt;li&gt;Copy the files, then run an &lt;code&gt;npm install&lt;/code&gt; to fetch the project&amp;#8217;s dependencies and run an &lt;code&gt;npm run build&lt;/code&gt; to create the production assets.&lt;/li&gt; &lt;li&gt;Start the second stage with a &lt;code&gt;FROM nginx:1.17&lt;/code&gt; statement and copy the files from the first stage into this new container.&lt;/li&gt; &lt;/ol&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: To avoid copying unnecessary files such as the &lt;code&gt;node_modules&lt;/code&gt; folders, create a &lt;code&gt;.docker-ignore&lt;/code&gt; file in the same folder as your &lt;code&gt;Dockerfile&lt;/code&gt; and list the folders to ignore. Also, note that the production code&amp;#8217;s location varies based on the JavaScript framework you are using, so uncomment the line you need. Angular requires that you change the name of your project manually.&lt;/p&gt; &lt;p&gt;Here is the complete Dockerfile at this stage:&lt;/p&gt; &lt;pre&gt;FROM node:14 WORKDIR /app COPY . . RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 WORKDIR /usr/share/nginx/html # Angular # COPY --from=0 /app/dist/&amp;#60;projectName&amp;#62; . # React # COPY --from=0 /app/build . # VueJS # COPY --from=0 /app/dist . &lt;/pre&gt; &lt;p&gt;After creating the Dockerfile, you can build the image and start the container to test it out. Run the following commands and open your browser to &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/"&gt;http://localhost:8080&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;docker build -t front-end. docker run -d -p 8080:80 --rm --name front frontend &lt;/pre&gt; &lt;p&gt;To stop the container after you&amp;#8217;ve tested it, enter:&lt;/p&gt; &lt;pre&gt;docker stop front&lt;/pre&gt; &lt;h2&gt;Inject the environment variables&lt;/h2&gt; &lt;p&gt;Next, you will edit the Dockerfile to inject your environment variables. First, you&amp;#8217;ll overwrite the content of your original &lt;code&gt;config.json&lt;/code&gt; file, then you&amp;#8217;ll tweak the NGINX server to inject the environment variables.&lt;/p&gt; &lt;h3&gt;Overwrite config.json&lt;/h3&gt; &lt;p&gt;Instead of having actual values, each property&amp;#8217;s value will be &amp;#8220;&lt;code&gt;$key&lt;/code&gt;&amp;#8220;. The resulting &lt;code&gt;config.json&lt;/code&gt; looks like this:&lt;/p&gt; &lt;pre&gt;{ ENV: "$ENV", BASE_URL: "$BASE_URL" } &lt;/pre&gt; &lt;p&gt;You will use the &lt;code&gt;envsubst&lt;/code&gt; to change the &lt;code&gt;$KEY&lt;/code&gt; values to the environment variable&amp;#8217;s real value just before the server starts. For this to work, you need to add instructions to the first step of the Dockerfile to include &lt;a target="_blank" rel="nofollow" href="https://stedolan.github.io/jq/manual/"&gt;jq&lt;/a&gt;, a tool that makes it easy to edit the contents of a JSON file from the CLI. Right after the &lt;code&gt;FROM&lt;/code&gt; line in your Dockerfile, add the following to install &lt;code&gt;jq&lt;/code&gt; in the container:&lt;/p&gt; &lt;pre&gt;ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq &lt;/pre&gt; &lt;p&gt;After the files have been copied, you can use &lt;code&gt;jq&lt;/code&gt; to edit the &lt;code&gt;config.json&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json &amp;#62; ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json ./src/config.json &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you want to learn more about the &lt;code&gt;jq&lt;/code&gt; filter used in this example and experiment with other options, you can run it in &lt;a target="_blank" rel="nofollow" href="https://jqterm.com"&gt;jqTerm&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Tweak the NGINX server&lt;/h3&gt; &lt;p&gt;After you&amp;#8217;ve modified the &lt;code&gt;config.json&lt;/code&gt; file, you will tweak the NGINX server to inject the environment variables. To do so, you will need to create a script to be executed before starting the NGINX server.&lt;/p&gt; &lt;p&gt;This file (&lt;code&gt;start-nginx.sh&lt;/code&gt;) contains quite a bit of bash scripting. The first line of the script runs a command to get the names of all existing environment variables and stores those in &lt;code&gt;$EXISTING_VARS&lt;/code&gt;. The script then loops through each JavaScript file in your production folder and replaces any &lt;code&gt;$VARIABLE&lt;/code&gt; with the actual value of that environment variable. Once it&amp;#8217;s done, it starts the NGINX server with the default command:&lt;/p&gt; &lt;pre&gt;#!/usr/bin/env bash export EXISTING_VARS=$(printenv | awk -F= '{print $1}' | sed 's/^/\$/g' | paste -sd,); for file in $JSFOLDER; do cat $file | envsubst $EXISTING_VARS | tee $file done nginx -g 'daemon off;' &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The location of the JavaScript files differs for each framework. The &lt;code&gt;$JSFOLDER&lt;/code&gt; variable is set in the Dockerfile so that you can uncomment the line you need there.&lt;/p&gt; &lt;p&gt;Now, add this file to the container and overwrite the NGINX image&amp;#8217;s default entry point with this new script. Right after the &lt;code&gt;FROM&lt;/code&gt; statement of the second stage, add the following lines for your framework:&lt;/p&gt; &lt;pre&gt;# Angular # ENV JSFOLDER=/usr/share/nginx/html/*.js # React # ENV JSFOLDER=/usr/share/nginx/html/static/js/*.js # VueJS # ENV JSFOLDER=/usr/share/nginx/html/js/*.js COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh &lt;/pre&gt; &lt;p&gt;At the very end of the file, add the new entry point:&lt;/p&gt; &lt;pre&gt;ENTRYPOINT [ "start-nginx.sh" ] &lt;/pre&gt; &lt;p&gt;Your final Dockerfile should look like this one. You can uncomment the required lines and remove all the other commented statements:&lt;/p&gt; &lt;pre&gt;FROM node:14 ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq WORKDIR /app COPY . . RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json &amp;#62; ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json ./src/config.json RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 # Angular # ENV JSFOLDER=/usr/share/nginx/html/*.js # React # ENV JSFOLDER=/usr/share/nginx/html/static/js/*.js # VueJS # ENV JSFOLDER=/usr/share/nginx/html/js/*.js COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh WORKDIR /usr/share/nginx/html # Angular # COPY --from=0 /app/dist/&amp;#60;projectName&amp;#62; . # React # COPY --from=0 /app/build . # VueJS # COPY --from=0 /app/dist . ENTRYPOINT [ "start-nginx.sh" ] &lt;/pre&gt; &lt;h2&gt;Rebuild your image and start the server&lt;/h2&gt; &lt;p&gt;You are now ready to rebuild your image and start the server again, but this time with environment variables. Open your browser at &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/"&gt;http://localhost:8080&lt;/a&gt;, and you should see the application running with the values of the environment variables you&amp;#8217;ve passed to Docker:&lt;/p&gt; &lt;pre&gt;docker build -t frontend . docker run -d -p 8080:80 --rm --name front -e ENV=prod -e BASE_URL=/api frontend &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In summary, here are the steps to make your environment variables accessible in your front-end containers:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Add a &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers/blob/main/config.json"&gt;config.json&lt;/a&gt; file in your &lt;code&gt;/src&lt;/code&gt; folder.&lt;/li&gt; &lt;li&gt;Add the &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers/blob/main/start-nginx.sh"&gt;start-nginx.sh&lt;/a&gt; bash script to your project.&lt;/li&gt; &lt;li&gt;Use the completed &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers/blob/main/Dockerfile"&gt;Dockerfile&lt;/a&gt; to build your project.&lt;/li&gt; &lt;li&gt;Start your container using &lt;code&gt;-e&lt;/code&gt; to specify the environment variables.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Once you&amp;#8217;ve created a Dockerfile following these steps, you can reuse it for any of your JavaScript projects. All the variables in the &lt;code&gt;config.json&lt;/code&gt; will change automatically, and you won&amp;#8217;t need to think about them anymore. You can find the complete source code and examples for the Angular, React, and Vue.js applications used in this article on &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/frontend-containers"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#38;linkname=Making%20environment%20variables%20accessible%20in%20front-end%20containers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fmaking-environment-variables-accessible-in-front-end-containers%2F&amp;#038;title=Making%20environment%20variables%20accessible%20in%20front-end%20containers" data-a2a-url="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/" data-a2a-title="Making environment variables accessible in front-end containers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/"&gt;Making environment variables accessible in front-end containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/bRQAOiM1CwA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;When building a container for a single-page application using any modern JavaScript framework (such as Angular, React, or Vue.js), you might find that the configuration settings are different depending on where the container will run. A typical case would be the base URL for your API, which will differ depending on whether you are testing [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/"&gt;Making environment variables accessible in front-end containers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">861157</post-id><dc:creator>Joel Lord</dc:creator><dc:date>2021-03-04T18:59:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/</feedburner:origLink></entry><entry><title>Building rootless containers for JavaScript front ends</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/u_E8Yo1oe3o/" /><category term="Containers" /><category term="JavaScript" /><category term="Kubernetes" /><category term="Node.js" /><category term="front end javascript" /><category term="nginx" /><category term="openshift" /><category term="rootless" /><category term="rootless container" /><author><name>Joel Lord</name></author><id>https://developers.redhat.com/blog/?p=861477</id><updated>2021-03-04T08:00:09Z</updated><published>2021-03-04T08:00:09Z</published><content type="html">&lt;p&gt;By default, most &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt; are run as the root user. It is much easier to install dependencies, edit files, and run processes on restricted ports when they run as root. As is usually the case in computer science, though, simplicity comes at a cost. In this case, containers run as root are more vulnerable to malicious code and attacks. To avoid those potential &lt;a href="https://developers.redhat.com/topics/security"&gt;security&lt;/a&gt; gaps, &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; won&amp;#8217;t let you run containers as a root user. This restriction adds a layer of security and isolates the containers.&lt;/p&gt; &lt;p&gt;This article shows you how to run a JavaScript front-end application in a rootless container. The example builds on the code from my previous article, &lt;a href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers"&gt;&lt;i&gt;Making environment variables accessible in front-end containers&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Building a rootless container&lt;/h2&gt; &lt;p&gt;Here is the Dockerfile we&amp;#8217;ll use for our example. As demonstrated in my &lt;a href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers/"&gt;previous article&lt;/a&gt;, you can use this Dockerfile to access environment variables from your Angular, React, or Vue.js applications:&lt;/p&gt; &lt;pre&gt;FROM node:14 ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq WORKDIR /app COPY . . RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json | ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json config.json RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 # Angular: ENV JSFOLDER=/usr/share/nginx/html/*.js # React: ENV JSFOLDER=/usr/share/nginx/html/static/js/*.js # VueJS: ENV JSFOLDER=/usr/share/nginx/html/js/*.js COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh WORKDIR /usr/share/nginx/html # Angular: COPY --from=0 /app/dist/ . # React: COPY --from=0 /app/build . # VueJS: COPY --from=0 /app/dist . ENTRYPOINT [ "start-nginx.sh" ] &lt;/pre&gt; &lt;p&gt;This container uses two stages to build the final container. In the first stage, it uses the &lt;code&gt;node:14&lt;/code&gt; image, which is running as root. The build process will eventually discard this container, so you don&amp;#8217;t need to worry about it.&lt;/p&gt; &lt;p&gt;The second-stage container is the one that needs to be secured. The &lt;code&gt;nginx&lt;/code&gt; base image is currently running as root, mainly so that it can run on port 80, which requires privileged access to enable. Once this container is ready to run rootless, it will run on port 8080. You will need to change the default &lt;code&gt;nginx&lt;/code&gt; configuration for the container to run rootless. You will also need to make sure that the server itself is running as an unprivileged user. Finally, the user will need access to several files and folders.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s get started with making this container a rootless one.&lt;/p&gt; &lt;h2&gt;Create the NGINX configuration file&lt;/h2&gt; &lt;p&gt;The first step is to create a new configuration file for NGINX. You can start with the most basic configuration file needed to run NGINX and build it from there:&lt;/p&gt; &lt;pre&gt;worker_processes auto; events { worker_connections 1024; } http { include /etc/nginx/mime.types; server { server_name _; index index.html; location / { try_files $uri /index.html; } } }&lt;/pre&gt; &lt;p&gt;Next, you need to change the server settings to run on port 8080 instead of the default port 80. You&amp;#8217;ll also need to change the default path that NGINX uses to serve files:&lt;/p&gt; &lt;pre&gt;http { ... server { listen 8080; ... location / { root /code; ... } } }&lt;/pre&gt; &lt;p&gt;The final &lt;code&gt;nginx.conf&lt;/code&gt; file should look like this:&lt;/p&gt; &lt;pre&gt;worker_processes auto; events { worker_connections 1024; } http { include /etc/nginx/mime.types; server { listen 8080; server_name _; index index.html; location / { root /opt/app; try_files $uri /index.html; } } }&lt;/pre&gt; &lt;h2&gt;Edit the Dockerfile&lt;/h2&gt; &lt;p&gt;Now that you have a new NGINX configuration file that lets the server run as a regular user, it&amp;#8217;s time to edit the Dockerfile. This modified container will run as user &lt;code&gt;nginx&lt;/code&gt;. In this case, the NGINX base images provide the non-root user.&lt;/p&gt; &lt;p&gt;In the second step of your build, right after you&amp;#8217;ve specified your base image with the &lt;code&gt;FROM&lt;/code&gt; statement, you can copy your new NGINX configuration file to overwrite the default one. Then, create an &lt;code&gt;/opt/app&lt;/code&gt; folder and change its ownership:&lt;/p&gt; &lt;pre&gt;FROM nginx:1.17 COPY ./nginx.conf /etc/nginx/nginx.conf RUN mkdir -p /opt/app &amp;#38;&amp;#38; chown -R nginx:nginx /opt/app &amp;#38;&amp;#38; chmod -R 775 /opt/app &lt;/pre&gt; &lt;p&gt;Don&amp;#8217;t forget to change the &lt;code&gt;JSFOLDER&lt;/code&gt; variable. This will ensure that your environment variables are still injected by the bash script.&lt;/p&gt; &lt;pre&gt;# Angular # ENV JSFOLDER=/opt/app/*.js # React # ENV JSFOLDER=/opt/app/static/js/*.js # VueJS # ENV JSFOLDER=/opt/app/js/*.js &lt;/pre&gt; &lt;h3&gt;Change the file ownership&lt;/h3&gt; &lt;p&gt;Next, you need to give NGINX access to run a series of files and folders for caching and logging purposes. You can change the ownership of all of them in a single &lt;code&gt;RUN&lt;/code&gt; statement, using ampersands to chain the commands:&lt;/p&gt; &lt;pre&gt;RUN chown -R nginx:nginx /var/cache/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/log/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /etc/nginx/conf.d &lt;/pre&gt; &lt;p&gt;NGINX also requires an &lt;code&gt;nginx.pid&lt;/code&gt; file. This file does not exist yet, so you need to create it and assign ownership to the &lt;code&gt;nginx&lt;/code&gt; user:&lt;/p&gt; &lt;pre&gt;RUN touch /var/run/nginx.pid &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/run/nginx.pid &lt;/pre&gt; &lt;h3&gt;Update the group and permissions&lt;/h3&gt; &lt;p&gt;Finally, you will change the group for those files and folders and change the permissions so that NGINX can read and write the folders:&lt;/p&gt; &lt;pre&gt;RUN chgrp -R root /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid &amp;#38;&amp;#38; \ chmod -R 775 /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid &lt;/pre&gt; &lt;h3&gt;Switch to the rootless user&lt;/h3&gt; &lt;p&gt;Now that you&amp;#8217;ve adjusted all the permissions, you can tell Docker to switch over to the &lt;code&gt;nginx&lt;/code&gt; user using the &lt;code&gt;USER&lt;/code&gt; statement. You can then copy the files from the builder step into the &lt;code&gt;/opt/app&lt;/code&gt; folder using the &lt;code&gt;--chown&lt;/code&gt; flag, which makes the files accessible by the &lt;code&gt;nginx&lt;/code&gt; user. Finally, you will tell Docker that this new image uses a different port. Use the &lt;code&gt;EXPOSE&lt;/code&gt; statement for port 8080:&lt;/p&gt; &lt;pre&gt;USER nginx WORKDIR /opt/app COPY --from=builder --chown=nginx . RUN chmod -R a+rw /opt/app EXPOSE 8080 &lt;/pre&gt; &lt;p&gt;The final front-end Dockerfile will look like this:&lt;/p&gt; &lt;pre&gt;FROM node:14 ENV JQ_VERSION=1.6 RUN wget --no-check-certificate https://github.com/stedolan/jq/releases/download/jq-${JQ_VERSION}/jq-linux64 -O /tmp/jq-linux64 RUN cp /tmp/jq-linux64 /usr/bin/jq RUN chmod +x /usr/bin/jq WORKDIR /app COPY . . RUN jq 'to_entries | map_values({ (.key) : ("$" + .key) }) | reduce .[] as $item ({}; . + $item)' ./src/config.json | ./src/config.tmp.json &amp;#38;&amp;#38; mv ./src/config.tmp.json config.json RUN npm install &amp;#38;&amp;#38; npm run build FROM nginx:1.17 # Angular # ENV JSFOLDER=/opt/app/*.js # React # ENV JSFOLDER=/opt/app/static/js/*.js # VueJS # ENV JSFOLDER=/opt/app/js/*.js COPY ./nginx.conf /etc/nginx/nginx.conf RUN mkdir -p /opt/app &amp;#38;&amp;#38; chown -R nginx:nginx /opt/app &amp;#38;&amp;#38; chmod -R 775 /opt/app RUN chown -R nginx:nginx /var/cache/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/log/nginx &amp;#38;&amp;#38; \ chown -R nginx:nginx /etc/nginx/conf.d RUN touch /var/run/nginx.pid &amp;#38;&amp;#38; \ chown -R nginx:nginx /var/run/nginx.pid RUN chgrp -R root /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid &amp;#38;&amp;#38; \ chmod -R 775 /var/cache/nginx /var/run /var/log/nginx /var/run/nginx.pid COPY ./start-nginx.sh /usr/bin/start-nginx.sh RUN chmod +x /usr/bin/start-nginx.sh EXPOSE 8080 WORKDIR /opt/app # Angular # COPY --from=0 --chown=nginx /app/dist/ . # React # COPY --from=0 /app/build . # VueJS # COPY --from=0 /app/dist . RUN chmod -R a+rw /opt/app USER nginx ENTRYPOINT [ "start-nginx.sh" ]&lt;/pre&gt; &lt;p&gt;Your new Dockerfile is ready to go! You can test it out by using a &lt;code&gt;docker build&lt;/code&gt; followed by a &lt;code&gt;docker run&lt;/code&gt;. Don&amp;#8217;t forget to map the new port since this container doesn&amp;#8217;t run on port 80 anymore:&lt;/p&gt; &lt;pre&gt;docker build -t frontend . docker run -d -p 8080:8080 --rm --name front -e ENV=prod -e BASE_URL=/api frontend &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;You now have everything needed to run your JavaScript front end in a secure container. You can reuse the image we developed in this article for all of your JavaScript projects, whether you are using Angular, React, or Vue.js. The front end not only runs securely but also lets you inject environment variables into your code. You can find all the examples and source code from this article on &lt;a target="_blank" rel="nofollow" href="http://github.com/joellord/frontend-containers"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#38;linkname=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F03%2F04%2Fbuilding-rootless-containers-for-javascript-front-ends%2F&amp;#038;title=Building%20rootless%20containers%20for%20JavaScript%20front%20ends" data-a2a-url="https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/" data-a2a-title="Building rootless containers for JavaScript front ends"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/"&gt;Building rootless containers for JavaScript front ends&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/u_E8Yo1oe3o" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;By default, most containers are run as the root user. It is much easier to install dependencies, edit files, and run processes on restricted ports when they run as root. As is usually the case in computer science, though, simplicity comes at a cost. In this case, containers run as root are more vulnerable to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/"&gt;Building rootless containers for JavaScript front ends&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">861477</post-id><dc:creator>Joel Lord</dc:creator><dc:date>2021-03-04T08:00:09Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/03/04/building-rootless-containers-for-javascript-front-ends/</feedburner:origLink></entry><entry><title type="html">Business optimisation architecture - Example vaccine scheduling</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3NJxyvEvNik/business-optimisation-architecture-example-vaccine-scheduling-.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/p3YFp6gjxCA/business-optimisation-architecture-example-vaccine-scheduling-.html</id><updated>2021-03-04T06:00:00Z</updated><content type="html">Part 4 - Example vaccine scheduling In  we looked at an example architecture for retail planning optimisation. It started with laying out the process of how I've approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. The specific example of how retail organisations can optimise delivery planning, employee rostering, and optimise task assignments was laid out in the architecture blueprint diagram. This article continues on with another specific example that focuses on how retail stores around the world are helping deliver vaccinations through their pharmacies. It walks you through an example optimisation scenario showing how to provide for customer vaccine scheduling. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's my intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but I've chosen a format that I hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. Now let's take a look at the details in this blueprint and outline the solution. VACCINE SCHEDULING ARCHITECTURE The example blueprint shown in the figure titled Schematic - Business optimisation (vaccine scheduling) outlines how this type of optimisation ties into your architecture. In this example, starting from the left we see a business owner and developer providing the input needed for the vaccine planning services. These inputs are constraints (both hard and soft), resource availability, and business goals to be achieved.  It's interesting to take a short side trip into the reason that various constraints make putting together a schedule so demanding that special tooling is needed. In the case of vaccination scheduling there are things you need to think about such as: * planning runs need to complete in timely fashion, for example: * ~350k slots should produce a schedule within an hour * runs can be done several times a day * if anyone with a slot cancels, the planning needs to stop it's run and start again * achieve continuous planning * need rules to prevent games the system, for example: * can't request a slot, then cancel if not satisfied with your slot, thereby getting an earlier slot * ensure cancelled slots in schedule go to back of the line * account for vaccine types that can't be given to certain age groups * give priority to second vaccine slot planning over first vaccine slot These are just some of the constraints and conditions that need to be met with regards to designing and executing a planning cycle. Something to think about, right? While this might look like something that the business owner and developer are doing into the fully deployed solution, it's really using the previously covered  showcased in that blueprint. For simplicity, we've included the planning and constraint development aspects here to help with an understanding that business owners are involved. The vaccine planning services can then be triggered or viewed by external systems shown as planners that have been given access through the API management element to start, provide input, or retreive planning optimisation results.  The integration microservices are making extensive use of the planning results to share a vaccine appointment with the user of the frontend application, shown here as a mobile application. Data access is shown at the bottom making use of vaccine center data, vaccine supply data, and customer data. Access for the vaccine planning services is arranged by the integration data microservices allowing for clean separation of integration points between critical demarcation lines of your architecture. While the business owner and developer are working on the constraints and modeling of the needed vaccine planning services, at runtime the rest of the elements in this diagram are leveraging these optimisation planning services to achieve desired outcomes.  The diagram might give the impression that this is a single in store pharmacy solution, but it can also be seen in the context of a centralised architecture in the retail organisation where the external status views are those of satellite stores or warehouses. The stores and warehouses are all looking to make use of the vaccine planning and optimising services for better pharmacy vaccine scheduling. WHAT'S NEXT THIS WAS JUST A SHORT OVERVIEW OF A VACCINE SCHEDULING ARCHITECTURE THAT PROVIDES YOU WITH A MAP TO SOLVE YOUR OWN BUSINESS OPTIMISATION CHALLENGES.  AN OVERVIEW OF THIS SERIES ON THE BUSINESS OPTIMISATION PORTFOLIO ARCHITECTURE BLUEPRINT CAN BE FOUND HERE: 1. 2. 3. 4. CATCH UP ON ANY ARTICLES YOU MISSED BY FOLLOWING ONE OF THE LINKS ABOVE. THIS COMPLETES THE SERIES AND WE HOPE YOU ENJOYED THIS ARCHITECTURE BLUEPRINT FOR BUSINESS OPTIMISATION. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3NJxyvEvNik" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/p3YFp6gjxCA/business-optimisation-architecture-example-vaccine-scheduling-.html</feedburner:origLink></entry><entry><title type="html">Optimizing COVID-19 vaccination appointment scheduling</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lMx0uG695YE/optimizing-covid-19-vaccination-appointment-scheduling.html" /><author><name>pauljamesbrown</name></author><id>https://blog.kie.org/2021/03/optimizing-covid-19-vaccination-appointment-scheduling.html</id><updated>2021-03-04T00:00:00Z</updated><content type="html">COVID-19 vaccination appointment scheduling has proven to be a world-wide challenge. People eligible for vaccinations haven’t been able to secure appointments despite repeated attempts. Those scheduled for vaccinations sometimes arrive at a vaccination center only to learn that their appointment has been canceled. Others find that they share the same vaccination time window with hundreds of people and must wait in line for hours. However, this doesn’t have to be the case. You can use the OptaPlanner vaccination appointment scheduler quickstart to develop a schedule that is both efficient and fair. The vaccination appointment scheduler uses artificial intelligence (AI) to prioritize people and allocate time slots based on multiple constraints and priorities. It is part of the , available on GitHub. Watch the video or read on to learn more. THE BENEFITS OF A SYSTEM-AUTOMATICALLY-ASSIGNS APPOINTMENT SCHEDULING SYSTEM There are two main approaches to scheduling appointments. The system can either let a person choose an appointment slot (user selects) or the system assigns a slot and tells the person when and where to attend (system automatically assigns). Here is a quick comparison of the two approaches: USER SELECTED SCHEDULING This approach is similar to the approach used with concert ticket sites such as Ticketmaster™. It’s how most concert tickets are sold. People compete with each other for a fixed number of tickets or appointments. Characteristics of this approach: * Appointments are available on a first-come first-serve basis. * A person chooses a preferred appointment time and location from a range of available appointments. Challenges with this approach: * First-come first-serve might not be fair. * System overloads can repeatedly shut out people with slower internet. * When many people try to reserve the same appointment slot at the same time, all but one person fails to secure the appointment which results in a poor user experience. Some people might give up trying to reserve an appointment. On the other hand, less desirable appointment slots might not be filled. * It’s tricky to prioritize based on criteria such as priority, age, or second dose status. * The desired vaccine type (Pfizer™, Moderna™, AstraZeneca™) might not be available. It could be argued that the user-selects method is not the most efficient method for vaccination scheduling. People can choose the closest vaccination center but that center might not have the greatest capacity. What’s good for one person isn’t always optimal for the population as a whole. There is no way for the system to direct a person to a vaccination center that meets the needs of the individual and is at the same time efficient for the entire population because of capacity. In addition, the system can easily be overloaded. SYSTEM AUTOMATICALLY ASSIGNED SCHEDULING With this push-based approach, people provide their information to the system and the system assigns an appointment. Characteristics of this approach: * Appointment slots are allocated based on priority. * The system allocates the best appointment time and location based on preconfigured planning constraints. Challenges with this approach: * The allocated time slot might not be convenient. * People might be more likely to reschedule. The system-automatically-assigns method is easier for people to use, is fairer, and is more efficient for vaccination appointment scheduling than the user-selects method. THE SECOND DOSE CHALLENGE Most COVID-19 vaccines require two doses. For optimal effectiveness, the second dose must be given within a specific time frame in relation to the first dose, using the same vaccine type. On top of that, different vaccines have different second-dose time frames. And within those time frames, there is a ready date (the first date that the second dose can be taken), an ideal date (the best date to take the second dose), and an end date (the last date that the second dose is considered to be effective). For example, the ideal date for the Pfizer second dose is 21 days after the first dose but the ideal date for the Moderna second dose is 28 days after the first dose. So let’s say that you start vaccinating people with the Moderna vaccine. After four weeks, you are still giving people the first dose, but now it’s time for people who already received their first dose to get their second dose. You have to decide whether to give an appointment to the person who needs the second dose or to give an appointment to someone for a first dose. That might seem like a no-brainer, but this scenario has potential complications. Let’s say that in the first week of vaccinations, you vaccinated people with a high priority but you also vaccinated other people as well because you found you had extra vaccines at the end of a day and you didn’t want to waste them. Now, four weeks later, you must choose whether to give an appointment to a first-dose high-priority person or give it to the lower-priority person that needs second dose. One solution is to equally share appointments between people receiving first and second doses, but doing this might create a backlog of people needing a second dose. If you keep giving the first dose without prioritizing people that need the second dose, eventually the backlog of people that need the second dose will snowball. The second dose vaccination date will move very far away from the ideal date and might exceed the due date which will make the first vaccination much less effective. Therefore, prioritize second-dose appointments over first-dose appointments regardless of the first-dose person’s priority rating. SOLVING THE VACCINATION APPOINTMENT SCHEDULING PROBLEM The OptaPlanner vaccination appointment scheduler uses the system-automatically-assigns method to solve the problem of vaccinating as many people as possible by using planning constraints to create a score for each person. The person’s score determines when they get an appointment. The higher the person’s score, the better chance they have of receiving an earlier appointment. Constraints are either hard, medium, or soft: * Hard constraints cannot be broken. If any hard constraint is broken, the plan is unfeasible and cannot be executed: * Capacity: Do not over-book vaccine capacity at any time at any location. * Vaccine max age: If a vaccine has a maximum age, do not administer it to people who at the time of the first dose vaccination are older than the vaccine maximum age. Ensure people are given a vaccine type appropriate for their age. For example, don’t assign a 75 year old person an appointment for a vaccine that has a maximum age restriction of 65 years. * Required vaccine type: Use the required vaccine type. For example, the second dose of a vaccine must be the same vaccine type as the first dose. * Ready date: Administer the vaccine on or after the specified date. For example, if a person receives a second dose, do not administer it before the recommended earliest possible vaccination date for the specific vaccine type (such as 26 days after the first dose). * Due date: Administer the vaccine on or before the specified date. For example, if a person receives a second dose, administer it before the recommended vaccination final due date for the specific vaccine (such as three months after the first dose). * Restrict maximum travel distance: Assign each person to one of a group of vaccination centers nearest to them. This is typically one of three centers. This restriction is calculated by travel time, not distance, so a person that lives in an urban area usually has a lower maximum distance to travel than a rural person. * Medium constraints decide who doesn’t get an appointment when there’s not enough capacity to assign appointments to everyone. This is called over-constrained planning: * Schedule second dose vaccinations: Do not leave any second dose vaccination appointments unassigned unless the ideal date falls outside of the planning window. * Schedule people based on their priority rating: Each person has a priority rating. This is typically their age but it can be much higher if they are, for example, a healthcare worker. Leave only people with the lowest priority ratings unassigned. They will be picked up in the next run. This constraint is softer than the previous constraint because the second dose is always prioritized over priority rating. * Soft constraints should not be broken: * Preferred vaccination center: If a person has a preferred vaccination center, give them an appointment at that center. * Distance: Minimize the distance that a person must travel to their assigned vaccination center. * Ideal date: Administer the vaccine on or as close to the specified date as possible. For example, if a person receives a second dose, administer it on the ideal date for the specific vaccine (such as 28 days after the first dose). This constraint is softer than the distance constraint to avoid sending people half-way across the country just to be one day closer to their ideal date. * Priority rating: Schedule people with a higher priority rating earlier in the planning window. This constraint is softer than the distance constraint to avoid sending people half-way across the country. This constraint is also softer than the ideal date constraint because the second dose is prioritized over priority rating. Hard constraints are weighted against other hard constraints. Soft constraints are weighted against other soft constraints. However, hard constraints always outweigh medium and soft constraints regardless of their respective weights. Because you have more people than you have appointment slots, you need to make tough decisions. Second dose appointments are always assigned first to avoid creating a backlog that would overwhelm you later. After that, people are assigned based on their priority rating. Everyone starts with a priority rating that is their age. Doing this prioritizes older people over younger people. After that, people that are in specific priority groups receive a few hundred extra points. This varies based on the priority of their group. For example, nurses might receive an extra 1000 points. This way, older nurses are prioritized over younger nurses and young nurses are prioritized over people who are not nurses. The following table illustrates this concept: THE SOLVER At the core of OptaPlanner is the solver, the engine that takes the problem data set and overlays the planning constraints and configurations. The problem data set includes all of the information about the people, the vaccines, and the vaccination centers. The solver works through the various combinations of data and eventually determines an optimized appointment schedule with people assigned to vaccination appointments at a specific center. The following illustration shows a schedule that the solver created: CONTINUOUS PLANNING Continuous planning is the technique of managing one or more upcoming planning periods at the same time and repeating that process monthly, weekly, daily, hourly, or even more frequently. The planning window advances incrementally by a specified interval. The following illustration shows a two week planning window that is updated daily: The two week planning window is divided in half. The first week is in the published state and the second week is in the draft state. People are assigned to appointments in both the published and draft parts of the planning window. However, only people in the published part of the planning window are notified of their appointments. The other appointments can still change easily in the next run. Doing this prevents the schedule from painting itself in a corner. For example, if a person who needs a second dose has a ready date of Monday and an ideal date of Wednesday, you don’t have to invite them for Monday if-and-only-if you can prove you can give them a draft appointment later in the week. You can determine the size of the planning window but just be mindful of the size of the problem space. The problem space is all of the various components that go into creating the schedule. So, the more days you plan ahead the larger the problem space. PINNED PLANNING ENTITIES If you are continuously planning on a daily basis, there will be appointments within the two week period that are already allocated to people. To ensure that appointments are not double-booked, you need to mark existing appointments as allocated by pinning them. Pinning is used to anchor one or more specific assignments and force OptaPlanner to schedule around those fixed assignments. A pinned planning entity, such as an appointment, doesn’t change during solving. Whether an entity is pinned or not is determined by the appointment state. If you take a look at the previous image, you can see to the left of the image that an appointment can have five states : Open, Invited, Accepted, Rejected, or Rescheduled. Table 1. Priority rating table Age Job Priority rating 60 nurse 1060 33 nurse 1033 71 retired 71 52 office worker 52 Note You don’t actually see these states directly in the quickstart demo code because the OptaPlanner engine is only interested in whether the appointment is pinned or not. So as you can see from the image, you need to be able to plan around appointments that have already been scheduled. An appointment with the Invited or Accepted state is pinned. Appointments with the Open, Reschedule, and Rejected state are not pinned and are available for scheduling. In this example, when the solver runs it searches across the entire two week planning window in both the published and draft ranges. The solver considers any unpinned entities (appointments with the Open, Reschedule, or Rejected states) in addition to the unscheduled input data, to find the optimal solution. If the solver is run daily, you will see a new day added to the schedule before you run the solver, as shown in the middle image above. The third schedule shows the results of the solver. Notice that the appointments on the new day have been assigned and Amy and Edna who were previously scheduled in the draft part of the planning window are now scheduled in the published part of the window. This was possible because Gus and Hugo requested a reschedule. This won’t cause any confusion because Amy and Edna were never notified about their draft dates. Now, because they have appointments in the published section of the planning window, they will be notified and asked to accept or reject their appointments, and their appointments are now pinned. Stay tuned. We’ll be posting a follow-up blog for a deeper, more technical look at the Optaplanner vaccination appointment scheduler quickstart. Additional resources * * * Co-authored by Emily Murphy. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lMx0uG695YE" height="1" width="1" alt=""/&gt;</content><dc:creator>pauljamesbrown</dc:creator><feedburner:origLink>https://blog.kie.org/2021/03/optimizing-covid-19-vaccination-appointment-scheduling.html</feedburner:origLink></entry></feed>
